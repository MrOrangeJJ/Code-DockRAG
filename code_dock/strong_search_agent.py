#!/usr/bin/env python3
"""
å¼ºæ•ˆä»£ç æœç´¢ä»£ç† - åŸºäºLLMçš„æ™ºèƒ½ä»£ç åº“æœç´¢å·¥å…·
è¿™ä¸ªå·¥å…·æ›´åŠ æ™ºèƒ½ï¼Œå¯ä»¥ä¸æ–­æ¢ç´¢ç›´åˆ°æ‰¾åˆ°æ»¡æ„ç­”æ¡ˆ
"""

import os
import json
import asyncio
import logging
from typing import Dict, List, Optional, Any, Set, Callable, Tuple
from openai import (
    AsyncOpenAI, 
    APITimeoutError, 
    APIConnectionError, 
    RateLimitError, 
    InternalServerError
)
import httpx # å¯¼å…¥ httpx
from tenacity import ( # å¯¼å…¥ tenacity ç›¸å…³æ¨¡å—
    retry, 
    stop_after_attempt,
    retry_if_result,
)

from pathlib import Path
import argparse
import sys
import time
from .treesitter import (
    generate_project_structure,
    generate_formatted_structure
)
from datetime import datetime # ç¡®ä¿å¯¼å…¥ datetime
from dotenv import load_dotenv
from .prompts import AGENT_INSTRUCTIONS
from .utils import get_codebase_path, load_config_file, load_lsp_cache, search_text
from agents import (
    Agent, Runner, OpenAIChatCompletionsModel, function_tool,
    Trace, Span, TracingProcessor, set_trace_processors, set_tracing_disabled,
    RunConfig,
)
import threading
import random

# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå³code_dockçš„çˆ¶ç›®å½•ï¼‰
root_dir = str(Path(os.path.dirname(os.path.abspath(__file__))).parent)
env_path = os.path.join(root_dir, '.env')
load_dotenv(env_path)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
    ]
)
logger = logging.getLogger(__name__)

# ä»ç¯å¢ƒå˜é‡è·å–æœ€å¤§è½®æ¬¡
MAX_TURNS = int(os.environ.get("STRONG_SEARCH_MAX_TURNS", "25"))  # è®¾ç½®é»˜è®¤å€¼

class StrongSearchAgent:
    """
    å¼ºæ•ˆä»£ç æœç´¢ä»£ç†ç±»ï¼Œå°è£…æ‰€æœ‰çŠ¶æ€å’ŒåŠŸèƒ½
    ä½¿ç”¨é¢å‘å¯¹è±¡æ–¹å¼å®ç°ï¼Œç¡®ä¿æ¯ä¸ªå®ä¾‹æœ‰è‡ªå·±ç‹¬ç«‹çš„çŠ¶æ€
    """
    def __init__(self, codebase_name: str):
        """
        åˆå§‹åŒ–ä»£ç æœç´¢ä»£ç†
        
        Args:
            codebase_name: ä»£ç åº“åç§°
        """
        self.codebase_name = codebase_name
        paths = get_codebase_path(codebase_name)
        self.project_root = paths["code"]  # ä»£ç åº“æ ¹ç›®å½•
        self.project_structure = {}  # é¡¹ç›®ç»“æ„
        self.relevant_files = set()  # ç›¸å…³æ–‡ä»¶é›†åˆ
        self.file_read_history = {}  # æ–‡ä»¶è¯»å–å†å²
        self.openai_client = None  # OpenAIå®¢æˆ·ç«¯

        self.analyzer_ready = load_config_file(codebase_name, "analyzer_ready")

        # åˆå§‹åŒ–é¡¹ç›®ç»“æ„
        try:
            self.project_structure = generate_formatted_structure(codebase_name)
        except Exception as e:
            logger.warning(f"åˆå§‹åŒ–é¡¹ç›®ç»“æ„æ—¶å‡ºé”™: {e}, å°†åœ¨éœ€è¦æ—¶é‡æ–°åŠ è½½")
            
    async def get_file_content(self, file_path: str) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šæ–‡ä»¶çš„å†…å®¹
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«æ–‡ä»¶å†…å®¹çš„å­—å…¸
        """
        # æ„å»ºå®Œæ•´è·¯å¾„
        if not os.path.isabs(file_path):
            full_path = os.path.join(self.project_root, file_path)
        else:
            full_path = file_path
        
        if not os.path.exists(full_path):
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æŒ‰æ–‡ä»¶ååŒ¹é…
            filename = os.path.basename(file_path)
            if not filename:
                return {
                    "file_path": file_path,
                    "content": "",
                    "message": f"Invalid file path: {file_path}, please provide the correct file path",
                    "note": "Please call wrapped_get_project_structure to better understand the project structure"
                }
            
            # åœ¨æ•´ä¸ªé¡¹ç›®ä¸­æœç´¢æ–‡ä»¶ååŒ¹é…çš„æ–‡ä»¶
            matched_files = []
            for root, dirs, files in os.walk(self.project_root):
                for file in files:
                    if file == filename:
                        rel_path = os.path.relpath(os.path.join(root, file), self.project_root)
                        matched_files.append(rel_path)
            
            # æ ¹æ®åŒ¹é…æ•°é‡å¤„ç†
            if len(matched_files) == 1:
                # åªæ‰¾åˆ°ä¸€ä¸ªåŒ¹é…ï¼Œè¿”å›å…¶å†…å®¹ä½†æé†’è·¯å¾„é”™è¯¯
                correct_path = matched_files[0]
                try:
                    with open(os.path.join(self.project_root, correct_path), 'r', encoding='utf-8', errors='replace') as f:
                        content = f.read()
                        self.file_read_history[correct_path] = content
                        return {
                            "file_path": correct_path,
                            "content": content,
                            "message": f"âš ï¸ Warning: The path '{file_path}' you provided is incorrect, but I found a file with the same name. The correct path is '{correct_path}'. Please use the correct path in subsequent queries.",
                            "note": "Please remember to use wrapped_mark_file_relevance to mark whether this file is relevant to the question, using the correct path"
                        }
                except Exception as e:
                    logger.error(f"Error reading matched file: {correct_path} - {e}")
            elif len(matched_files) > 1:
                # æ‰¾åˆ°å¤šä¸ªåŒ¹é…ï¼Œä¸è¿”å›å†…å®¹ï¼Œæé†’ç¡®è®¤
                paths_list = "\n".join([f"- {path}" for path in matched_files])
                return {
                    "file_path": file_path,
                    "content": "",
                    "message": f"âš ï¸ Warning: The path '{file_path}' you provided is incorrect, but I found {len(matched_files)} files with the same name. Please confirm which one you're looking for:\n{paths_list}",
                    "note": "Please call wrapped_get_project_structure to understand the project structure better, and then use the correct complete path to query again"
                }
                
            # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å›åŸå§‹é”™è¯¯
            return {
                "file_path": file_path,
                "content": "",
                "message": f"File does not exist: {file_path}, please ensure your file_path is correct (don't hastily conclude that the file truly doesn't exist, please recheck the project file paths)",
                "note": "Please call wrapped_get_project_structure to understand the project structure better, ensuring you use the correct relative path"
            }
        
        try:
            with open(full_path, 'r', encoding='utf-8', errors='replace') as f:
                content = f.read()
                self.file_read_history[file_path] = content
                return {
                    "file_path": file_path,
                    "content": content,
                    "message": "Successfully read file content",
                    "note": "Please remember to use wrapped_mark_file_relevance to mark whether this file is relevant to the question"
                }
        except Exception as e:
            logger.error(f"Error reading file: {full_path} - {e}")
            return {
                "file_path": file_path,
                "content": "",
                "message": f"Error reading file: {str(e)}",
                "note": "Please remember to use wrapped_mark_file_relevance to mark whether this file is relevant to the question"
            }

    async def mark_file_relevance(self, file_path: str, is_relevant: bool) -> Dict[str, Any]:
        """
        æ ‡è®°æ–‡ä»¶æ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            is_relevant: æ˜¯å¦ç›¸å…³
            
        Returns:
            æ“ä½œç»“æœ
        """
        if is_relevant:
            self.relevant_files.add(file_path)
            message = f"File {file_path} has been marked as relevant"
        else:
            # å¦‚æœæ–‡ä»¶åœ¨ç›¸å…³æ–‡ä»¶é›†åˆä¸­ï¼Œåˆ™ç§»é™¤
            if file_path in self.relevant_files:
                self.relevant_files.remove(file_path)
                message = f"File {file_path} has been marked as not relevant"
            else:
                message = f"File {file_path} is already marked as not relevant"
        
        return {
            "file_path": file_path,
            "is_relevant": is_relevant,
            "message": message
        }

    async def get_project_structure(self, random_string: str = "") -> Dict[str, Any]:
        """
        è·å–å½“å‰é¡¹ç›®çš„ç»“æ„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶å’Œç›®å½•çš„æ ‘çŠ¶å›¾
        
        Args:
            random_string: æ— ç”¨å‚æ•°ï¼Œåªæ˜¯ä¸ºäº†æ»¡è¶³å·¥å…·è°ƒç”¨è¦æ±‚
            
        Returns:
            é¡¹ç›®ç»“æ„ä¿¡æ¯ï¼ˆåŒæ—¶åŒ…å«åŸå§‹ç»“æ„å’Œæ–‡æœ¬è¡¨ç¤ºï¼‰
        """
        logger.info("Tool: Getting project structure... " + self.codebase_name)
        try:
            # å¦‚æœé¡¹ç›®ç»“æ„ä¸ºç©ºï¼Œåˆ™é‡æ–°åŠ è½½
            if not self.project_structure:
                self.project_structure = generate_formatted_structure(self.codebase_name)
            
            return {
                "structure": self.project_structure,
                "message": "Current project structure information"
            }
        except Exception as e:
            return {
                "structure": {},
                "message": f"Failed to get project structure: {str(e)}"
            }

    def _create_tool_functions(self) -> List[Callable]:
        """åˆ›å»ºå·¥å…·å‡½æ•°åˆ—è¡¨ï¼Œå°†å®ä¾‹æ–¹æ³•åŒ…è£…ä¸ºfunction_tool"""

        # --- å·¥å…·å®šä¹‰ ---

        @function_tool
        async def wrapped_get_file_content(file_path: str) -> Dict[str, Any]:
            """Retrieves the complete content of a specific file from the codebase.

            If the provided file_path doesn't exist, the tool will attempt to find files with the same name across the project.
            If a unique match is found, it will return its content while noting the path error.
            If multiple matches are found, it will ask for a more precise path.

            Args:
                file_path: The relative path to the file from the project root directory.

            Returns:
                A dictionary containing the file path, content, and status messages.
            """
            return await self.get_file_content(file_path)
            
        @function_tool
        async def wrapped_mark_file_relevance(file_path: str, is_relevant: bool) -> Dict[str, Any]:
            """Marks whether a file is relevant to the current user query.

            The list of relevant files will be used in the context for the final answer.

            Args:
                file_path: The relative path of the file to mark.
                is_relevant: Boolean indicating whether the file is relevant (True) or not (False).

            Returns:
                A dictionary containing the operation status.
            """
            return await self.mark_file_relevance(file_path, is_relevant)
            
        @function_tool
        async def wrapped_get_project_structure(random_string: str = "") -> Dict[str, Any]:
            """Retrieves an overview of the current codebase structure.

            Returns a formatted text representation of the hierarchical structure, including files, classes, and methods,
            to help understand the code organization.
            Note: This tool doesn't accept actual parameters; random_string is only used to satisfy the interface.

            Returns:
                A dictionary containing the formatted structure text and status message.
            """
            # æ³¨æ„ï¼šè¿™é‡Œçš„ random_string å‚æ•°æ˜¯ä¸ºäº†å…¼å®¹æ€§ï¼Œå®é™…æœªä½¿ç”¨
            return await self.get_project_structure(random_string)
            
        @function_tool
        async def wrapped_find_code_references(symbol_name: str, file_path: Optional[str] = None) -> Dict[str, Any]:
            """Finds all references to a specified symbol (function or class) throughout the codebase.

            Similar to the 'Go to References' functionality in IDEs. Can search within a specific file or across the entire project.

            Args:
                symbol_name: The name of the function or class to find references for.
                file_path: The relative path to the file containing the function or class definition. (Required)

            Returns:
                A dictionary containing a list of references or error message. References include file paths and line numbers where the symbol is referenced.
            """
            return await self.find_references(file_path, symbol_name)
        
        @function_tool
        async def wrapped_search_text(keyword: str) -> Dict[str, Any]:
            """Searches for files in the codebase containing the specified keyword.

            Args:
                keyword: The keyword to search for.

            Returns:
                A dictionary containing the search results.
            """
            return search_text(self.codebase_name, keyword)

        # --- å·¥å…·åˆ—è¡¨ ---
        tools_list = [
            wrapped_get_file_content, 
            wrapped_mark_file_relevance, 
            wrapped_get_project_structure,
            wrapped_search_text
        ]
        
        if self.analyzer_ready:
            tools_list.append(wrapped_find_code_references)
            
        return tools_list

    async def run_search(self, query: str, trace_id: str = None, tracing_disabled: bool = False) -> Dict[str, Any]:
        """
        è¿è¡Œä»£ç æœç´¢ï¼Œæ ¸å¿ƒæ‰§è¡Œå‡½æ•°
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            trace_id: å¯é€‰çš„è¿½è¸ªIDï¼Œç”¨äºå…³è”å¤„ç†å™¨
            tracing_disabled: æ˜¯å¦ç¦ç”¨è¿½è¸ªï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å…¨å±€è®¾ç½®
            
        Returns:
            Dict[str, Any]: åŒ…å«æœç´¢ç»“æœçš„å­—å…¸
        """
        # å‡†å¤‡å·¥å…·å‡½æ•°
        tool_functions = self._create_tool_functions()
        
        # æ¯æ¬¡è¿è¡Œæ—¶è·å–å½“å‰çš„ç¯å¢ƒå˜é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨os.getenvï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°å€¼
        model_base_url = os.environ.get("MODEL_BASE_URL", "")
        model_api_key = os.environ.get("MODEL_API_KEY", "")
        
        
        # åˆ›å»ºå®¢æˆ·ç«¯æ—¶ä¼ å…¥è‡ªå®šä¹‰çš„ http_client
        self.openai_client = AsyncOpenAI(
            base_url=model_base_url,
            api_key=model_api_key,
            http_client=CustomRetryClient() # ä½¿ç”¨è‡ªå®šä¹‰å®¢æˆ·ç«¯
            # æ³¨æ„: AsyncOpenAI è‡ªèº«çš„ max_retries åœ¨ä½¿ç”¨è‡ªå®šä¹‰ http_client æ—¶å¯èƒ½ä¸å†ç”Ÿæ•ˆæˆ–è¡Œä¸ºæ”¹å˜
        )
        
        # åˆ›å»ºä»£ç† 
        try:
            # è·å–å½“å‰ç¯å¢ƒå˜é‡ä¸­çš„æ¨¡å‹åç§°
            model = os.environ.get("MODEL_NAME", "gpt-3.5-turbo")
            
            # åŠ¨æ€è·å–æœ€å¤§è½®æ¬¡ï¼Œå¦‚æœç¯å¢ƒå˜é‡å·²æ›´æ–°åˆ™ä½¿ç”¨æ–°å€¼
            max_turns = int(os.environ.get("STRONG_SEARCH_MAX_TURNS", str(MAX_TURNS)))
            
            
            agent = Agent(
                name="Code Search Expert",
                instructions=AGENT_INSTRUCTIONS.format(query=query),
                tools=tool_functions,
                model=OpenAIChatCompletionsModel(
                    model=model,
                    openai_client=self.openai_client,
                )
            )
        except Exception as agent_init_e:
            logger.error(f"Failed to create Agent: {agent_init_e}", exc_info=True)
            return {"answer": f"Internal error: Unable to initialize search agent", 
                   "relevant_files": [], 
                   "execution_time": 0}
        
        # å‡†å¤‡åˆå§‹æ¶ˆæ¯
        messages = [
            {"role": "system", "content": "You are a code search expert who can answer user questions about codebases by exploring project structure and code content."},
            {"role": "user", "content": f"I need to answer a question about this project: \"{query}\". Please start by analyzing the project structure."}
        ]
        
        logger.info(f"Running Agent Runner (Max Turns: {max_turns})...")
        result_data = {}
        start_time = time.time()
        try:
            # åˆ›å»ºRunConfigé…ç½®
            run_config = RunConfig(
                trace_id=trace_id,  # ä½¿ç”¨ä¼ å…¥çš„trace_id
                tracing_disabled=tracing_disabled,
                workflow_name=f"Code Search - {self.codebase_name}",
                trace_metadata={"codebase": self.codebase_name, "query": query}
            )
            
            # ä½¿ç”¨RunConfigï¼Œå¹¶ä¸”ä½¿ç”¨åŠ¨æ€è·å–çš„æœ€å¤§è½®æ¬¡
            result = await Runner.run(
                agent, 
                input=messages, 
                max_turns=max_turns,  # ä½¿ç”¨å½“å‰ç¯å¢ƒå˜é‡ä¸­çš„è®¾ç½®
                run_config=run_config
            )
            final_answer = getattr(result, 'final_output', "Failed to get final output")
            
        except Exception as agent_run_error:
            logger.error(f"Agent Runner.run execution error: {agent_run_error}", exc_info=True)
            final_answer = f"Agent execution failed: {agent_run_error}"
        finally:
            execution_time = time.time() - start_time
            result_data = {
                "answer": final_answer,
                "project_structure": self.project_structure,  # æ·»åŠ é¡¹ç›®ç»“æ„åˆ°ç»“æœä¸­
                "relevant_files": sorted(list(self.relevant_files)),  # ç¡®ä¿é¡ºåºä¸€è‡´
                "execution_time": execution_time,
                "file_read_history": self.file_read_history,  # æ·»åŠ æ–‡ä»¶è¯»å–å†å²
                "trace_id": trace_id  # è¿”å›trace_idï¼Œæ–¹ä¾¿å®¢æˆ·ç«¯å…³è”
            }
            
        logger.info(f"Agent Runner completed, time taken: {execution_time:.2f}s")
        return result_data
    
    async def find_references(self, file_path, symbol_name):
        """
        å¼‚æ­¥æŸ¥æ‰¾æŒ‡å®šç¬¦å·çš„å¼•ç”¨
        
        Args:
            file_path: ç¬¦å·æ‰€åœ¨æ–‡ä»¶è·¯å¾„
            symbol_name: ç¬¦å·åç§°
            symbol_type: ç¬¦å·ç±»å‹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            dict: åŒ…å«çŠ¶æ€ã€æ¶ˆæ¯å’Œç»“æœçš„å­—å…¸
        """

        formatted_refs = {"status": "success", "message": "", "file_path": file_path, "result": []}
        cache = load_lsp_cache(self.codebase_name)

        rel_path = os.path.relpath(file_path, self.project_root) if os.path.isabs(file_path) else file_path
        full_path = os.path.join(self.project_root, rel_path)
        if not os.path.exists(full_path):
            filename = os.path.basename(file_path)
            if not filename:
                formatted_refs["status"] = "failed"
                formatted_refs["message"] = f"Invalid file path: {file_path}, please provide the correct file path. Please call wrapped_get_project_structure to better understand the project structure"
                return formatted_refs

                
        if rel_path not in cache.keys():
            formatted_refs["status"] = "failed"
            formatted_refs["message"] = "File provided not found, please check the file path and call wrapped_get_project_structure to re-analyze the project structure"
            return formatted_refs
        
        file_symbols = cache[rel_path]
         
        # 1. å°è¯•ç›´æ¥ç²¾ç¡®åŒ¹é…
        if symbol_name in file_symbols:
            formatted_refs["result"] = file_symbols[symbol_name]
            return formatted_refs
        else:
            # 2. å°è¯•æŸ¥æ‰¾éƒ¨åˆ†åŒ¹é… - ç¬¦å·æœ«å°¾åŒ¹é…
            exact_suffix_matches = [s for s in file_symbols.keys() if s.endswith(f".{symbol_name}") or s == symbol_name]
            if len(exact_suffix_matches) == 1:
                formatted_refs["result"] = file_symbols[exact_suffix_matches[0]]
                return formatted_refs
            elif len(exact_suffix_matches) > 1:
                # å¤šä¸ªæœ«å°¾åŒ¹é…ï¼Œåˆ—å‡ºæ‰€æœ‰å¯èƒ½
                formatted_refs["status"] = "warning"
                formatted_refs["message"] = f"Found multiple symbols matching '{symbol_name}':\n"
                for m in exact_suffix_matches:
                    formatted_refs["message"] += f"- {m}\n"
                formatted_refs["message"] += "Please choose a more specific name"
                return formatted_refs
            else:
                # 3. å¦‚æœæ²¡æœ‰ç²¾ç¡®åç¼€åŒ¹é…ï¼Œå°è¯•åŒ…å«åŒ¹é… symbol_name in symbol
                contains_matches = []
                for s in file_symbols.keys():
                    # ç§»é™¤å‚æ•°éƒ¨åˆ†ï¼ˆå¦‚æœ‰ï¼‰ï¼Œåªæ¯”è¾ƒæ–¹æ³•å
                    base_name = symbol_name.split('(')[0] if '(' in symbol_name else symbol_name
                    s_base = s.split('(')[0] if '(' in s else s
                    
                    if base_name in s_base:
                        contains_matches.append(s)
                
                if len(contains_matches) == 1:
                    formatted_refs["result"] = file_symbols[contains_matches[0]]
                    return formatted_refs
                elif len(contains_matches) > 1:
                    # å¤šä¸ªåŒ…å«åŒ¹é…ï¼Œåˆ—å‡ºæ‰€æœ‰å¯èƒ½
                    formatted_refs["status"] = "warning"
                    formatted_refs["message"] = f"Found multiple symbols containing '{symbol_name}':\n"
                    for i, m in enumerate(contains_matches):
                        formatted_refs["message"] += f"{i+1}. {m}\n"
                    formatted_refs["message"] += "Please choose a more specific name"
                    return formatted_refs
        
        formatted_refs["status"] = "failed"
        formatted_refs["message"] = f"No symbols matching '{symbol_name}' were found"
        return formatted_refs

# å…¼å®¹æ€§å‡½æ•° - ä¿æŒåŸæœ‰APIçš„å‘åå…¼å®¹æ€§
async def run_agent(codebase_name: str, query: str, trace_id: str = None, tracing_disabled: bool = None) -> Dict[str, Any]:
    """
    è¿è¡Œä»£ç æœç´¢ä»£ç†ã€‚å…¼å®¹æ—§çš„APIè°ƒç”¨æ–¹å¼ã€‚
    
    Args:
        codebase_name: ä»£ç åº“åç§°
        query: ç”¨æˆ·æŸ¥è¯¢
        trace_id: å¯é€‰çš„è¿½è¸ªIDï¼Œç”¨äºå…³è”å¤„ç†å™¨
        tracing_disabled: æ˜¯å¦ç¦ç”¨è¿½è¸ªï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å…¨å±€è®¾ç½®
        
    Returns:
        ä»£ç†çš„æœ€ç»ˆè¾“å‡ºå’Œç›¸å…³æ–‡ä»¶
    """
    # åˆ›å»ºä»£ç†å®ä¾‹
    agent = StrongSearchAgent(codebase_name)
    
    # è¿è¡Œæœç´¢
    result = await agent.run_search(query, trace_id=trace_id, tracing_disabled=tracing_disabled)
    
    # ä»ç»“æœä¸­ç§»é™¤æ–‡ä»¶è¯»å–å†å²ï¼Œä¿æŒè¿”å›æ ¼å¼å…¼å®¹
    if "file_read_history" in result:
        del result["file_read_history"]
    
    return result
    

# ---------------- å…¨å±€WebSocketè¿½è¸ªå¤„ç†å™¨ ----------------
class GlobalWebSocketTracingProcessor(TracingProcessor):
    """å…¨å±€WebSocketè¿½è¸ªå¤„ç†å™¨ï¼Œå†…éƒ¨è·¯ç”±åˆ°å…·ä½“å®¢æˆ·ç«¯"""
    def __init__(self):
        self.routes = {}  # {trace_id: (client_id, manager, timestamp)}
        self.lock = threading.Lock()
        self.cleanup_threshold = 3600  # 1å°æ—¶æœªæ´»åŠ¨çš„è·¯ç”±å°†è¢«æ¸…ç†
        logger.info("[GlobalWebSocketTracingProcessor] åˆå§‹åŒ–")
    
    def register(self, trace_id: str, client_id: str, manager: Any):
        """æ³¨å†Œä¸€ä¸ªæ–°çš„trace_idåˆ°ç‰¹å®šå®¢æˆ·ç«¯"""
        with self.lock:
            self.routes[trace_id] = (client_id, manager, time.time())
        logger.info(f"[GlobalWebSocketTracingProcessor] æ³¨å†Œtrace_id: {trace_id} -> client_id: {client_id}")
    
    def unregister(self, trace_id: str):
        """æ³¨é”€ä¸€ä¸ªtrace_id"""
        with self.lock:
            if trace_id in self.routes:
                del self.routes[trace_id]
                logger.info(f"[GlobalWebSocketTracingProcessor] æ³¨é”€trace_id: {trace_id}")
    
    def _get_client_manager(self, obj) -> Tuple[str, Any, float]:
        """è·å–å¯¹åº”traceçš„å®¢æˆ·ç«¯IDå’Œç®¡ç†å™¨"""
        trace_id = getattr(obj, 'trace_id', None)
        if not trace_id:
            return None, None, 0
            
        with self.lock:
            return self.routes.get(trace_id, (None, None, 0))
    
    def cleanup_expired_routes(self):
        """æ¸…ç†è¿‡æœŸçš„è·¯ç”±"""
        now = time.time()
        expired_routes = []
        
        with self.lock:
            for trace_id, (client_id, _, timestamp) in self.routes.items():
                if now - timestamp > self.cleanup_threshold:
                    expired_routes.append(trace_id)
            
            for trace_id in expired_routes:
                del self.routes[trace_id]
                logger.info(f"[GlobalWebSocketTracingProcessor] æ¸…ç†è¿‡æœŸè·¯ç”±: {trace_id}")
    
    def _format_message(self, span: Span[Any], client_id: str) -> Optional[Dict[str, Any]]:
        """ä»Spanæ ¼å¼åŒ–WebSocketæ¶ˆæ¯"""
        try:
            # è¾…åŠ©å‡½æ•°ï¼šä»å¤šä¸ªå¯èƒ½çš„æ¥æºæå–å·¥å…·åç§°
            def extract_tool_name(obj) -> str:
                tool_name = None
                # ç›´æ¥ä»å±æ€§è·å–
                if not tool_name and hasattr(obj, 'function_name') and obj.function_name:
                    tool_name = obj.function_name
                if not tool_name and hasattr(obj, 'tool_name') and obj.tool_name:
                    tool_name = obj.tool_name
                if not tool_name and hasattr(obj, 'name') and obj.name:
                    tool_name = obj.name
                
                # ä»å­—å…¸æ•°æ®ä¸­è·å–
                if not tool_name and isinstance(obj, dict):
                    if 'function_name' in obj and obj['function_name']:
                        tool_name = obj['function_name']
                    elif 'name' in obj and obj['name']:
                        tool_name = obj['name']
                    elif 'function' in obj and isinstance(obj['function'], dict):
                        if 'name' in obj['function'] and obj['function']['name']:
                            tool_name = obj['function']['name']
                
                # ä»inputä¸­è·å–
                if not tool_name and hasattr(obj, 'input'):
                    input_data = obj.input
                    if isinstance(input_data, dict):
                        if 'function_name' in input_data and input_data['function_name']:
                            tool_name = input_data['function_name']
                        elif 'name' in input_data and input_data['name']:
                            tool_name = input_data['name']
                
                # æœ€åçš„fallback
                if not tool_name:
                    tool_name = "æœªçŸ¥å·¥å…·"
                
                return tool_name
                
            span_type_name = type(span.span_data).__name__
            span_data = span.span_data
            message = None
            level = "info" # é»˜è®¤çº§åˆ«
            
            # å®‰å…¨è·å–manager
            trace_id = getattr(span, 'trace_id', '')
            with self.lock:
                route_info = self.routes.get(trace_id)
                
            if not route_info:
                logger.warning(f"æœªæ‰¾åˆ°trace_idä¸º{trace_id}çš„è·¯ç”±ä¿¡æ¯")
                return None
                
            _, manager, _ = route_info

            if span_type_name == 'GenerationSpanData':
   
                output_content = "[æ— è¾“å‡º]"
                tool_call_decision = None
                if hasattr(span_data, 'output') and span_data.output:
                    try:
                        if isinstance(span_data.output, list) and len(span_data.output) > 0 and isinstance(span_data.output[0], dict):
                            assistant_message = span_data.output[0].get('content')
                            tool_calls = span_data.output[0].get('tool_calls')
                            if assistant_message:
                                output_content = f'{assistant_message[:150]}...'
                                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨ç†å†…å®¹ï¼Œå‘é€ä¸ºagent_thinkingç±»å‹
                                if "æˆ‘æ¥æ€è€ƒ" in assistant_message or "æˆ‘éœ€è¦åˆ†æ" in assistant_message or "è®©æˆ‘æ€è€ƒ" in assistant_message:
                                    asyncio.create_task(manager.send_log(
                                        client_id, 
                                        assistant_message, 
                                        level="agent_thinking"
                                    ))
                                    return None
                            elif tool_calls:
                                tool_details = []
                                for tc in tool_calls:
                                    # ä½¿ç”¨å…¬å…±æå–å‡½æ•°
                                    name = extract_tool_name(tc)
                                    function_data = tc.get('function', {})
                                    tool_details.append({"tool_name": name, "parameters": function_data.get('arguments', {})})
                                output_content = f"å†³å®šè°ƒç”¨å·¥å…·: {', '.join([d['tool_name'] for d in tool_details])}"
                                tool_call_decision = tool_details # ä¿å­˜å†³ç­–è¯¦æƒ…
                        else:
                            output_content = f'{json.dumps(span_data.output, ensure_ascii=False, default=str)[:100]}...'
                    except Exception as e:
                        output_content = f"[æ— æ³•è§£æè¾“å‡º: {str(e)}]"
                
                if tool_call_decision:
                     # å‘é€æ¯ä¸ªå·¥å…·è°ƒç”¨å†³ç­–
                     for decision in tool_call_decision:
                         asyncio.create_task(manager.send_log(client_id, decision, level="tool_call_decision"))
                     # ä¸å†å‘é€åˆå¹¶çš„æ€è€ƒæ¶ˆæ¯
                     return None 
                else:
                     message = f"ğŸ§  Agent æ€è€ƒ/å†³ç­–: {output_content}"
                     level = "info"
                     if hasattr(span_data, 'error') and span_data.error:
                         message += f" (é”™è¯¯: {span_data.error})"
                         level = "error"
                     
                     # å°†æ€è€ƒ/å†³ç­–å†…å®¹ä½œä¸ºagent_thinkingç±»å‹å‘é€
                     if "æ€è€ƒ" in output_content or "åˆ†æ" in output_content or "æŸ¥çœ‹" in output_content:
                        asyncio.create_task(manager.send_log(
                            client_id, 
                            output_content, 
                            level="agent_thinking"
                        ))
                        return None
                
            elif span_type_name == 'FunctionSpanData':

                # ä½¿ç”¨å…¬å…±æå–å‡½æ•°è·å–å·¥å…·åç§°
                tool_name = extract_tool_name(span_data)
                
                params = {}
                if hasattr(span_data, 'input'):
                    try: 
                        if isinstance(span_data.input, str):
                            params = json.loads(span_data.input)
                        elif isinstance(span_data.input, dict):
                            params = span_data.input
                        else:
                            params = {"raw_input": str(span_data.input)[:200]}
                    except Exception as e: 
                        params = {"raw_input": str(span_data.input)[:200]}
                
                # ç¡®ä¿paramsæ˜¯JSONå¯åºåˆ—åŒ–çš„
                try:
                    # æµ‹è¯•åºåˆ—åŒ–
                    json.dumps(params, ensure_ascii=False, default=str)
                except Exception as e:
                    # å¦‚æœä¸å¯åºåˆ—åŒ–ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                    params = {"raw_input": str(params)[:200]}
                    
                # å‘é€å·¥å…·è°ƒç”¨ä¿¡æ¯
                tool_call_message = {"tool_name": tool_name, "parameters": params, "timestamp": time.time()}
                asyncio.create_task(manager.send_log(client_id, tool_call_message, level="tool_call"))
                
                # å‘é€å·¥å…·è¾“å‡ºä¿¡æ¯
                output_preview = "[æ— è¾“å‡ºæˆ–æ— æ³•è§£æ]"
                output_level = "tool_output"
                if hasattr(span_data, 'error') and span_data.error:
                    output_preview = f"âŒ è°ƒç”¨å¤±è´¥: {span_data.error}"
                    output_level = "error" # å°†é”™è¯¯ä¹Ÿè§†ä¸ºä¸€ç§è¾“å‡º
                elif hasattr(span_data, 'output'):
                    try: output_preview = f'{json.dumps(span_data.output, ensure_ascii=False, default=str)}'
                    except: pass # ä¿æŒé»˜è®¤
                
                tool_output_message = {"tool_name": tool_name, "output_preview": output_preview, "is_output": True, "timestamp": time.time()}
                asyncio.create_task(manager.send_log(client_id, tool_output_message, level=output_level))
                return None # å·²åˆ†å¼€å‘é€è°ƒç”¨å’Œè¾“å‡ºï¼Œä¸è¿”å›åˆå¹¶æ¶ˆæ¯
            elif span_type_name == "Reasoning" or span_type_name == "ReasoningStep" or span_type_name == "AgentReasoning":
                # ä¸“é—¨å¤„ç†æ¨ç†/æ€è€ƒç±»å‹çš„Span
                thinking_content = ""
                if hasattr(span_data, 'thinking') and span_data.thinking:
                    thinking_content = span_data.thinking
                elif hasattr(span_data, 'reasoning') and span_data.reasoning:
                    thinking_content = span_data.reasoning
                elif hasattr(span_data, 'content') and span_data.content:
                    thinking_content = span_data.content
                elif hasattr(span_data, 'prompt') and span_data.prompt:
                    thinking_content = span_data.prompt
                
                if thinking_content:
                    # é€šè¿‡å•ç‹¬çš„æ¶ˆæ¯ç±»å‹å‘é€Agentæ€è€ƒå†…å®¹
                    asyncio.create_task(manager.send_log(
                        client_id, 
                        thinking_content, 
                        level="agent_thinking"
                    ))
                return None
            else:
                # å…¶ä»– Span ç±»å‹æš‚æ—¶åªè®°å½•åˆ°æœåŠ¡å™¨æ—¥å¿—ï¼Œä¸å‘é€åˆ°å‰ç«¯
                logger.debug(f"[WebSocketTracer] Skipping span type: {span_type_name} for client {client_id}")
                return None
                
            # è¿”å›æ ¼å¼åŒ–çš„æ™®é€šæ¶ˆæ¯ (å¦‚æœé€‚ç”¨)
            return {"message": message, "level": level}
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return None
    
    def on_span_end(self, span: Span[Any]) -> None:
        client_id, manager, _ = self._get_client_manager(span)
        if not client_id or not manager:
            return

        try:
            formatted = self._format_message(span, client_id)
            if formatted:
                 # å‘é€æ ¼å¼åŒ–çš„æ¶ˆæ¯
                 asyncio.create_task(manager.send_log(client_id, formatted["message"], level=formatted["level"]))
        except Exception as e:
            logger.error(f"å¤„ç†span_endäº‹ä»¶æ—¶å‡ºé”™: {e}")

    def on_trace_start(self, trace: Trace) -> None: 
        client_id, manager, _ = self._get_client_manager(trace)
        if not client_id or not manager:
            return
            
        try:
            logger.debug(f"[GlobalWebSocketTracer] Trace Start: {getattr(trace, 'trace_id', 'N/A')} for client {client_id}")
        except Exception as e:
            logger.error(f"å¤„ç†trace_startäº‹ä»¶æ—¶å‡ºé”™: {e}")
            
    def on_trace_end(self, trace: Trace) -> None: 
        client_id, manager, _ = self._get_client_manager(trace)
        if not client_id or not manager:
            return
            
        try:
            logger.debug(f"[GlobalWebSocketTracer] Trace End: {getattr(trace, 'trace_id', 'N/A')} for client {client_id}")
            
            # è‡ªåŠ¨æ³¨é”€å®Œæˆçš„trace
            self.unregister(getattr(trace, 'trace_id', None))
            
            # å‘¨æœŸæ€§æ¸…ç†è¿‡æœŸè·¯ç”±
            if random.random() < 0.1:  # 10%æ¦‚ç‡æ‰§è¡Œæ¸…ç†
                self.cleanup_expired_routes()
        except Exception as e:
            logger.error(f"å¤„ç†trace_endäº‹ä»¶æ—¶å‡ºé”™: {e}")
            
    def on_span_start(self, span: Span[Any]) -> None: 
        client_id, manager, _ = self._get_client_manager(span)
        if not client_id or not manager:
            return
            
        try:
            logger.debug(f"[GlobalWebSocketTracer] Span Start: {getattr(span, 'span_id', 'N/A')} for client {client_id}")
        except Exception as e:
            logger.error(f"å¤„ç†span_startäº‹ä»¶æ—¶å‡ºé”™: {e}")
            
    def shutdown(self) -> None:
        # æ¸…ç©ºæ‰€æœ‰è·¯ç”±
        with self.lock:
            self.routes.clear()
            
    def force_flush(self) -> None:
        pass


# ---------------- å…¨å±€æ–‡ä»¶æ—¥å¿—è¿½è¸ªå¤„ç†å™¨ ----------------
class GlobalFileTracingProcessor(TracingProcessor):
    """å…¨å±€æ–‡ä»¶è¿½è¸ªå¤„ç†å™¨ï¼Œå†…éƒ¨è·¯ç”±åˆ°å…·ä½“æ—¥å¿—å¤„ç†å™¨"""
    def __init__(self):
        self.routes = {}  # {trace_id: (log_handler, timestamp)}
        self.lock = threading.Lock()
        self.cleanup_threshold = 3600  # 1å°æ—¶æœªæ´»åŠ¨çš„è·¯ç”±å°†è¢«æ¸…ç†
        logger.info("[GlobalFileTracingProcessor] åˆå§‹åŒ–")
    
    def register(self, trace_id: str, log_handler: logging.FileHandler):
        """æ³¨å†Œä¸€ä¸ªæ–°çš„trace_idåˆ°ç‰¹å®šæ—¥å¿—å¤„ç†å™¨"""
        with self.lock:
            self.routes[trace_id] = (log_handler, time.time())
        logger.info(f"[GlobalFileTracingProcessor] æ³¨å†Œtrace_id: {trace_id}")
    
    def unregister(self, trace_id: str):
        """æ³¨é”€ä¸€ä¸ªtrace_id"""
        with self.lock:
            if trace_id in self.routes:
                del self.routes[trace_id]
                logger.info(f"[GlobalFileTracingProcessor] æ³¨é”€trace_id: {trace_id}")
    
    def _get_log_handler(self, obj) -> Tuple[logging.FileHandler, float]:
        """è·å–å¯¹åº”traceçš„æ—¥å¿—å¤„ç†å™¨"""
        trace_id = getattr(obj, 'trace_id', None)
        if not trace_id:
            return None, 0
            
        with self.lock:
            return self.routes.get(trace_id, (None, 0))
    
    def cleanup_expired_routes(self):
        """æ¸…ç†è¿‡æœŸçš„è·¯ç”±"""
        now = time.time()
        expired_routes = []
        
        with self.lock:
            for trace_id, (_, timestamp) in self.routes.items():
                if now - timestamp > self.cleanup_threshold:
                    expired_routes.append(trace_id)
            
            for trace_id in expired_routes:
                del self.routes[trace_id]
                logger.info(f"[GlobalFileTracingProcessor] æ¸…ç†è¿‡æœŸè·¯ç”±: {trace_id}")
    
    def _log_trace(self, log_handler: logging.FileHandler, message: str, level=logging.INFO):
        try:
            formatter = logging.Formatter('[TRACE:%(levelname)s] %(asctime)s - %(message)s')
            record = logging.LogRecord(
                name='tracing', level=level, 
                pathname="", lineno=0, msg=message, 
                args=(), exc_info=None, func=""
            )
            # æ‰‹åŠ¨æ·»åŠ æ—¶é—´æˆ³ï¼Œå› ä¸º FileHandler å¯èƒ½ä¸ä¼šè‡ªåŠ¨æ ¼å¼åŒ–
            record.asctime = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S,%f')[:-3]
            formatted_message = formatter.format(record)
            # ç›´æ¥å†™å…¥ï¼Œé¿å…ä¾èµ– root logger é…ç½®
            log_handler.stream.write(formatted_message + log_handler.terminator)
            log_handler.flush() # ç¡®ä¿å†™å…¥
        except Exception as e:
            print(f"Error logging trace to file: {e}") # æ‰“å°åˆ°æ§åˆ¶å°ä»¥é˜²æ—¥å¿—ç³»ç»Ÿæœ¬èº«å‡ºé—®é¢˜
            logger.error(f"Error logging trace to file: {e}", exc_info=True)
            
    def _format_span_details(self, span: Span[Any]) -> str:
        span_data = span.span_data
        details = {}
        if hasattr(span_data, 'tool_name'): details["Tool"] = span_data.tool_name
        elif hasattr(span_data, 'function_name'): details["Tool"] = span_data.function_name
        
        if hasattr(span_data, 'input'): 
            try: details["Input"] = json.dumps(span_data.input, ensure_ascii=False, default=str)
            except: details["Input"] = "[Cannot Serialize]"
            
        if hasattr(span_data, 'output'):
            try: details["Output"] = json.dumps(span_data.output, ensure_ascii=False, default=str)
            except: details["Output"] = "[Cannot Serialize]"
            
        if hasattr(span_data, 'error') and span_data.error: details["Error"] = str(span_data.error)
        
        return json.dumps(details, ensure_ascii=False) if details else ""

    def on_trace_start(self, trace: Trace) -> None:
        log_handler, _ = self._get_log_handler(trace)
        if not log_handler:
            return
            
        self._log_trace(log_handler, f"Trace Start: ID={getattr(trace, 'trace_id', 'N/A')}, Name={getattr(trace, 'name', '')}")

    def on_trace_end(self, trace: Trace) -> None:
        log_handler, _ = self._get_log_handler(trace)
        if not log_handler:
            return
            
        duration_str = "N/A"
        if hasattr(trace, 'end_time_ns') and hasattr(trace, 'start_time_ns') and trace.end_time_ns and trace.start_time_ns:
            try: duration_ms = (trace.end_time_ns - trace.start_time_ns) / 1_000_000; duration_str = f"{duration_ms:.2f}ms"
            except: duration_str = "ErrorCalculatingDuration"
        
        self._log_trace(log_handler, f"Trace End: ID={getattr(trace, 'trace_id', 'N/A')}, Duration={duration_str}")
        
        # è‡ªåŠ¨æ³¨é”€å®Œæˆçš„trace
        self.unregister(getattr(trace, 'trace_id', None))
        
        # å‘¨æœŸæ€§æ¸…ç†è¿‡æœŸè·¯ç”±
        if random.random() < 0.1:  # 10%æ¦‚ç‡æ‰§è¡Œæ¸…ç†
            self.cleanup_expired_routes()
    
    def on_span_start(self, span: Span[Any]) -> None:
        log_handler, _ = self._get_log_handler(span)
        if not log_handler:
            return
            
        span_type = type(span.span_data).__name__
        self._log_trace(log_handler, f"Span Start: ID={getattr(span, 'span_id', 'N/A')}, Type={span_type}, Parent={getattr(span, 'parent_id', 'N/A')}")

    def on_span_end(self, span: Span[Any]) -> None:
        log_handler, _ = self._get_log_handler(span)
        if not log_handler:
            return
            
        span_type = type(span.span_data).__name__
        duration_ms_str = "N/A"
        if hasattr(span, 'duration_ms') and span.duration_ms is not None:
             try: duration_ms_str = f"{span.duration_ms:.2f}ms"
             except: duration_ms_str = "ErrorCalculatingDuration"
        
        details_str = self._format_span_details(span)        
        msg = f"Span End: ID={getattr(span, 'span_id', 'N/A')}, Type={span_type}, Duration={duration_ms_str}" 
        if details_str: msg += f", Details: {details_str}"
        self._log_trace(log_handler, msg)
    
    def shutdown(self) -> None:
        # æ¸…ç©ºæ‰€æœ‰è·¯ç”±
        with self.lock:
            self.routes.clear()
            
    def force_flush(self) -> None:
        # å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ´»è·ƒçš„æ—¥å¿—å¤„ç†å™¨
        with self.lock:
            for trace_id, (log_handler, _) in self.routes.items():
                if log_handler:
                    try:
                        log_handler.flush()
                    except:
                        pass
                        
# åˆ›å»ºå…¨å±€å¤„ç†å™¨å®ä¾‹
global_ws_processor = GlobalWebSocketTracingProcessor()
global_file_processor = GlobalFileTracingProcessor()


# --- Tenacity é‡è¯•é…ç½® ---
def check_code(value):
    return value.status_code in [429]

# å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„ç­‰å¾…ç­–ç•¥
def custom_wait_strategy(retry_state):
    """è‡ªå®šä¹‰ç­‰å¾…ç­–ç•¥ï¼Œå¯¹429é”™è¯¯ä½¿ç”¨å›ºå®š40ç§’ï¼Œå…¶ä»–ä½¿ç”¨æŒ‡æ•°é€€é¿"""

    # å¯¹å…¶ä»–é”™è¯¯ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
    exp_delay = min(1 * (2 ** (retry_state.attempt_number+1)), 30)
    randomized_delay = exp_delay * (0.75 + (random.random() * 0.5))  # æ·»åŠ 25%çš„éšæœºæŠ–åŠ¨
    return randomized_delay


# å®šä¹‰å•ä¸€é‡è¯•ç­–ç•¥ï¼ˆä¸å†åˆ†å¼€å¤„ç†ä¸åŒç±»å‹çš„é”™è¯¯ï¼‰
unified_retry = retry(
    retry=retry_if_result(check_code),
    wait=custom_wait_strategy,  # ä½¿ç”¨è‡ªå®šä¹‰ç­‰å¾…ç­–ç•¥
    stop=stop_after_attempt(5), # æœ€å¤šé‡è¯•5æ¬¡
    reraise=True,              # é‡æ–°æŠ›å‡ºåŸå§‹å¼‚å¸¸
    before_sleep=lambda retry_state: logger.warning(
        f"å‡†å¤‡ç¬¬{retry_state.attempt_number}æ¬¡é‡è¯•, "
        f"å°†ç­‰å¾…{retry_state.next_action.sleep}ç§’"
    )
)

class CustomRetryTransport(httpx.AsyncHTTPTransport):
    """è‡ªå®šä¹‰HTTPä¼ è¾“å±‚ï¼Œæ·»åŠ é‡è¯•æœºåˆ¶"""
    
    @unified_retry
    async def handle_async_request(self, request: httpx.Request) -> httpx.Response:
        """å¤„ç†å¼‚æ­¥HTTPè¯·æ±‚ï¼Œæ·»åŠ é‡è¯•åŠŸèƒ½"""
        response = await super().handle_async_request(request)
        return response
            

# --- è‡ªå®šä¹‰ HTTP å®¢æˆ·ç«¯ ---

def CustomRetryClient(**kwargs) -> httpx.AsyncClient:
    """åˆ›å»ºä¸€ä¸ªé…ç½®äº†è‡ªå®šä¹‰é‡è¯• Transport çš„ httpx å®¢æˆ·ç«¯"""
    # å¯ä»¥ä¼ é€’å…¶ä»– httpx.AsyncClient å‚æ•°ï¼Œä¾‹å¦‚ timeout
    # ç¡®ä¿ä¼ é€’çš„ timeout ä¸æ˜¯ NotGiven ç±»å‹
    timeout = kwargs.pop('timeout', httpx.Timeout(60.0)) # é»˜è®¤60ç§’è¶…æ—¶
    limits = kwargs.pop('limits', httpx.Limits(max_connections=100, max_keepalive_connections=20))
    
    return httpx.AsyncClient(
        transport=CustomRetryTransport(), 
        timeout=timeout,
        limits=limits,
        **kwargs # ä¼ é€’ä»»ä½•é¢å¤–çš„ httpx å‚æ•°
    )

if __name__ == "__main__":
    pass